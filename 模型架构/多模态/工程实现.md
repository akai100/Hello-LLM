## 1. 多模态系统的工程整体架构

工程视觉的总图：

```css
        ┌─────────┐
        │  图像   │ → Vision Encoder ┐
        ├─────────┤                  │
        │  音频   │ → Audio Encoder  ├→ Adapter / Projector
        ├─────────┤                  │
        │  视频   │ → Video Encoder  ┘
        └─────────┘
                                        ↓
                                大语言模型（LLM）
                                        ↓
                                解码 / 推理 / 生成
```

**👉 核心思想：** 各模态负责“感知”，LLM 负责“理解 + 推理 + 表达”

## 2. 模态编码器（Encoder）怎么做

### 2.1 图像编码器（Vision Encoder）

**常见选择**

+ ViT（Vision Transformer）✅主流

+ ResNet（老但稳定）

**工程细节**

```
图片 → resize → patchify → embedding → ViT → feature map
```

ViT 输出一般是：

+ $[N_{patches} + 1, D]$

+ 比如：$[197. 768]$

**工程关键点**

+ ❗冻结参数（freeze）是常态

+ 用**预训练权重**（ImageNet / CLIP）

### 2.2 音频编码器

### 2.3 视频编码器

## 3. 模态对齐的算法实现

### 3.1 对比学习（CLIP-style）

**训练目标**

```
image_i ↔ text_i 是正样本
image_i ↔ text_j 是负样本
```

**损失函数**

$$L=−log(exp(sim(i,t)/τ)/Σexp(sim(i,t_k)/τ))$$

**工程细节**

+ 大 batch 非常重要（影响负样本数）

+ 常用 cosine similarity

+ 分布式训练（DDP）

### 3.2 Cross-Attention（LLM 多模态核心）

**结构**

```
Text Token ← Attention ← Image Token
```

**PyTorch 伪代码**

```python3
attn = softmax(Q_text @ K_img.T)
fused = attn @ V_img
```

工程要点：

+ Image token 数量控制（否则 O(n²)）

+ 常用 Perceiver / Resampler 压缩

## 4. Adapter / Projector

**为什么要 Adapter？**

+ Vision encoder 输出维度 ≠ LLM embedding

+ 不想微调整个 LLM（太贵）

**常见做法**

```
image_feat (768)
   ↓ Linear / MLP
llm_feat (4096)
```

**代码示意**

```python3
self.projector = nn.Sequential(
    nn.Linear(768, 4096),
    nn.GELU(),
    nn.Linear(4096, 4096)
)
```

## 5. 和 LLM 怎么“接线”？

### 5.1 Token 拼接法（最主流）

```
[BOS] <ImageToken> <ImageToken> ... 文本 tokens
```

工程技巧：

+ Image token 数量固定

+ 用特殊 token 占位

### 5.2 Cross-Attention 注入（更强）

+ 在 LLM 某几层插 cross-attn

+ 类似 Flamingo

优点：推理强

缺点：改模型结构，工程复杂

## 6. 训练策略

**阶段一：对齐训练（Alignment）**

+ 冻结 LLM

+ 冻结 Vision Encoder

+ **只训练 Adapter**

数据：

+ 图文对

+ 图像描述

目标：

+ 让模型“看懂图”

**阶段二：指令微调（Instruction Tuning）**

+ 多模态指令数据

```
{
  "image": "...",
  "question": "这张图里有什么？",
  "answer": "..."
}
```

+ 允许微调 LLM 的部分层

**阶段三：强化 / 偏好对齐（可选）**

+ RLHF / DPO

+ 减少幻觉

## 7. 推理与部署工程问题

### 1️⃣ 性能优化

+ Vision encoder 只跑一次（cache）

+ FP16 / INT8

+ Image token 压缩

### 2️⃣ 幻觉控制

+ 加 I don't know 样本

+ 加 bounding box / grounding

+ 置信度估计

### 3️⃣ 长上下文

+ 图像 token + 文本 token = 爆

+ Sliding window / Memory
