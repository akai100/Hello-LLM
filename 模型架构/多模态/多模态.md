## 多模态是什么

多模态学习是指联合建模来自不同模态（如图像、文本、音频、视频）的信息，实现理解、对齐与生成。

## 三大核心问题

### 1️⃣ 表示

+ 不同模态如何编码到向量空间？

### 2️⃣ 对齐（Alignment）

+ 图像区域 ↔ 文本 token

+ 语义是否一致？

### 3️⃣ 融合（Fusion）

+ 什么时候、在哪里、怎么融合？

## 多模态系统的经典架构

### 1️⃣ 双塔（Two-Tower / Dual Encoder）

```
Image Encoder → v_img
Text Encoder  → v_txt
```

+ 文本塔 + 图像塔

+ 中间用对比学习对齐

代表：

+ CLIP

+ ALIGN

优点：可扩展、训练稳定

缺点：深度推理能力有限

### 2️⃣ 统一 Transformer（Single-stream）

+ 所有模态都转成 token

+ 送入同一个 Transformer

代表：

+ GPT-4V

+ Flamingo

+ Gemini

优点：推理能力强、像“通用大脑”

缺点：训练成本极高

### 3️⃣ 编码器 + 大语言模型（LLM as Brain）

+ 图像/音频 → 编码器

+ 编码结果喂给 LLM 推理

代表：

+ LLaVA

+ MiniGPT-4

优点：性价比高、易扩展

缺点：对齐质量依赖编码器

## 多模态系统的核心流程

一个典型的多模态模型，通常包含 4 个关键步骤：

### 1️⃣ 模态编码（Modality Encoding）

把不同模态的数据，转换成模型能理解的向量表示：

| 模态 | 常见编码方式                        |
| -- | ----------------------------- |
| 文本 | Transformer / BERT / GPT      |
| 图像 | CNN / Vision Transformer（ViT） |
| 音频 | Mel Spectrogram + Transformer |
| 视频 | 3D CNN / 时序 Transformer       |

📌 目标：**把“异构信息”映射到一个可对齐的向量空间**

### 2️⃣ 模态对齐（Alignment）

解决一个核心问题：“这句话描述的是这张图里的哪个部分？”

例如：

+ “一只狗在草地上跑”

+ 图像中狗的位置、动作要和文字对齐

常见方式：

+ 对比学习（Contrastive Learning）

+ 跨模态注意力（Cross-Attention）

+ 共享语义空间（Shared Embedding Space）

代表模型：**CLIP**

### 3️⃣ 模态融合（Fusion）

把不同模态的信息“融合”起来进行推理：

融合方式主要有三类：

**🔹 早期融合（Early Fusion）**

+ 原始特征直接拼接

+ 简单，但噪声大

**🔹 中期融合（Mid Fusion）✅（最常见）**

+ 各自编码 → 注意力机制融合

+ 表达能力强、效果好

**🔹 后期融合（Late Fusion）**

+ 各模态独立决策 → 投票/加权

+ 工程友好，但语义交互弱

### 4️⃣ 跨模态生成 / 推理

多模态模型最终可以：

+ 🖼️ → 📝（看图说话）

+ 📝 → 🖼️（文生图）

+ 🎧 → 📝（语音转文字）

+ 📝 + 🖼️ → 📝（图文问答）

+ 🎥 → 📝（视频理解）
